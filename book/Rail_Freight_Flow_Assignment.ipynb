{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "595c56ad",
   "metadata": {},
   "source": [
    "## 1. Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa4640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "from shapely.geometry import LineString\n",
    "from shapely.ops import linemerge\n",
    "import igraph as ig\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import os\n",
    "from collections import defaultdict, deque\n",
    "from itertools import chain\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Output directory\n",
    "OUT_EDGES_DIR = Path(\"/soge-home/projects/mistral/miraca/processed_data/processed_unimodal/edges_with_flow\")\n",
    "OUT_EDGES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_DIR = OUT_EDGES_DIR\n",
    "\n",
    "# Map extent\n",
    "LON_MIN, LON_MAX = -12, 32\n",
    "LAT_MIN, LAT_MAX = 35, 72\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962c38be",
   "metadata": {},
   "source": [
    "## 2. Helper Functions\n",
    "\n",
    "Import helper functions from utils module or define them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaee8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from miraca_flow_utils if available, or define helpers here\n",
    "try:\n",
    "    from miraca_flow_utils import (\n",
    "        _pick_col, _ensure_metric_length, _compute_travel_time_kh,\n",
    "        build_igraph_from_edges, map_stations_to_nodes, compute_edge_capacity_tons,\n",
    "        od_flow_allocation_capacity_constrained, plot_edges_by_flow_thickness\n",
    "    )\n",
    "    print(\"✓ Imported helpers from miraca_flow_utils\")\n",
    "except ImportError:\n",
    "    print(\"⚠ miraca_flow_utils not found; define functions inline or ensure module is in path\")\n",
    "    # Define helpers inline if needed (copy from original script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9089be59",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f4af5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading data...\", flush=True)\n",
    "\n",
    "# Country boundaries\n",
    "countries_path = r\"/soge-home/projects/mistral/miraca/incoming_data/spatial_data/admin/ne_10m/ne_10m_admin_0_countries.shp\"\n",
    "europe_shape = gpd.read_file(countries_path)\n",
    "europe_bounds = {\"xmin\": -12, \"xmax\": 32, \"ymin\": 35, \"ymax\": 72}\n",
    "europe_shape = europe_shape.cx[europe_bounds[\"xmin\"]:europe_bounds[\"xmax\"], europe_bounds[\"ymin\"]:europe_bounds[\"ymax\"]]\n",
    "\n",
    "# Rail network\n",
    "rail_edges_file = \"/soge-home/projects/mistral/miraca/processed_data/processed_unimodal/europe_railways_edges_TENT.parquet\"\n",
    "rail_nodes_file = \"/soge-home/projects/mistral/miraca/processed_data/processed_unimodal/europe_railways_nodes_TENT.parquet\"\n",
    "rail_stations_file = \"/soge-home/projects/mistral/miraca/processed_data/processed_unimodal/europe_railways_stations_TENT.parquet\"\n",
    "od_flows_file = \"/soge-home/projects/mistral/miraca/processed_data/lifelines_OD/rail_freight_ths_tons_OD.parquet\"\n",
    "\n",
    "edges_gdf = gpd.read_parquet(rail_edges_file)\n",
    "nodes_gdf = gpd.read_parquet(rail_nodes_file)\n",
    "stations_df = gpd.read_parquet(rail_stations_file)\n",
    "od_flows = pd.read_parquet(od_flows_file)\n",
    "\n",
    "# Ensure CRS\n",
    "if edges_gdf.crs is None: edges_gdf.set_crs(\"EPSG:4326\", inplace=True, allow_override=True)\n",
    "if nodes_gdf.crs is None: nodes_gdf.set_crs(\"EPSG:4326\", inplace=True, allow_override=True)\n",
    "\n",
    "# Compute travel time\n",
    "edges_gdf = _compute_travel_time_kh(edges_gdf, speed_col='tag_maxspeed')\n",
    "\n",
    "# Assign edge IDs\n",
    "edges_gdf = edges_gdf.copy()\n",
    "edges_gdf['edge_id'] = np.arange(len(edges_gdf), dtype=int)\n",
    "\n",
    "print(f\"✓ Loaded {len(edges_gdf)} edges, {len(nodes_gdf)} nodes, {len(stations_df)} stations\")\n",
    "print(f\"✓ Loaded {len(od_flows)} OD pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6d4668",
   "metadata": {},
   "source": [
    "## 4. Prepare OD Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87194897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns\n",
    "edge_src = _pick_col(edges_gdf, ['from_id'])\n",
    "edge_dst = _pick_col(edges_gdf, ['to_id'])\n",
    "node_id_col = _pick_col(nodes_gdf, ['id'])\n",
    "station_id_col = _pick_col(stations_df, ['id'])\n",
    "\n",
    "# Map stations to nodes\n",
    "station2node = map_stations_to_nodes(stations_df, nodes_gdf, \n",
    "                                    station_id_col_candidates=(station_id_col,), \n",
    "                                    node_id_col=node_id_col)\n",
    "\n",
    "# Prepare OD\n",
    "if 'origin_sector' not in od_flows.columns:\n",
    "    od_flows['origin_sector'] = 'UNKNOWN'\n",
    "\n",
    "od = od_flows.copy()\n",
    "od['from_node'] = od['from_id'].astype(str).map(station2node)\n",
    "od['to_node'] = od['to_id'].astype(str).map(station2node)\n",
    "od = od.dropna(subset=['from_node', 'to_node'])\n",
    "od['from_node'] = od['from_node'].astype(str)\n",
    "od['to_node'] = od['to_node'].astype(str)\n",
    "od['value'] = pd.to_numeric(od['value'], errors='coerce').fillna(0.0)\n",
    "od = od[od['value'] > 0]\n",
    "\n",
    "print(f\"✓ Valid OD pairs: {len(od)}\")\n",
    "print(f\"✓ Total freight: {od['value'].sum():,.0f} tons/day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7ab488",
   "metadata": {},
   "source": [
    "## 5. Build Simplified Station-to-Station Network\n",
    "\n",
    "This step creates a simplified network where each edge represents a path between consecutive stations. This dramatically reduces the number of edges while preserving capacity bottlenecks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9271c754",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BUILDING SIMPLIFIED STATION-TO-STATION NETWORK\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Build station-to-station paths (BFS between consecutive stations)\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# Map stations to nodes\n",
    "sx = stations_df.geometry.x.to_numpy()\n",
    "sy = stations_df.geometry.y.to_numpy()\n",
    "nx_arr = nodes_gdf.geometry.x.to_numpy()\n",
    "ny = nodes_gdf.geometry.y.to_numpy()\n",
    "tree = cKDTree(np.column_stack([ny, nx_arr]))\n",
    "_, idx = tree.query(np.column_stack([sy, sx]))\n",
    "\n",
    "station_ids = stations_df[station_id_col].astype(str).to_numpy()\n",
    "node_ids = nodes_gdf.iloc[idx][node_id_col].astype(str).to_numpy()\n",
    "station_to_node = dict(zip(station_ids, node_ids))\n",
    "node_to_station = {v: k for k, v in station_to_node.items()}\n",
    "\n",
    "# Build adjacency list\n",
    "adjacency = defaultdict(list)\n",
    "edge_data = {}\n",
    "\n",
    "for idx_row, row in edges_gdf.iterrows():\n",
    "    src = str(row[edge_src])\n",
    "    dst = str(row[edge_dst])\n",
    "    edge_id = row['edge_id']\n",
    "    \n",
    "    edge_info = {\n",
    "        'edge_id': edge_id,\n",
    "        'to_node': dst,\n",
    "        'travel_time': float(row['travel_time']),\n",
    "        'geometry': row.geometry\n",
    "    }\n",
    "    adjacency[src].append(edge_info)\n",
    "    \n",
    "    edge_info_rev = edge_info.copy()\n",
    "    edge_info_rev['to_node'] = src\n",
    "    adjacency[dst].append(edge_info_rev)\n",
    "    \n",
    "    edge_data[edge_id] = edge_info\n",
    "\n",
    "# Find paths between consecutive stations using BFS\n",
    "paths = []\n",
    "station_nodes = set(station_to_node.values())\n",
    "processed_pairs = set()\n",
    "\n",
    "for idx_s, (start_station_id, start_node) in enumerate(station_to_node.items()):\n",
    "    if idx_s % 100 == 0 and idx_s > 0:\n",
    "        print(f\"  Processed {idx_s}/{len(station_to_node)} stations, found {len(paths)} paths...\")\n",
    "    \n",
    "    visited = {}\n",
    "    queue = deque([(start_node, [], 0)])\n",
    "    \n",
    "    while queue:\n",
    "        current_node, path_edges, path_length = queue.popleft()\n",
    "        \n",
    "        if current_node in visited:\n",
    "            if visited[current_node][1] <= path_length:\n",
    "                continue\n",
    "        visited[current_node] = (path_edges, path_length)\n",
    "        \n",
    "        if current_node in station_nodes and current_node != start_node:\n",
    "            end_station_id = node_to_station[current_node]\n",
    "            pair = tuple(sorted([start_station_id, end_station_id]))\n",
    "            if pair in processed_pairs:\n",
    "                continue\n",
    "            processed_pairs.add(pair)\n",
    "            \n",
    "            if path_edges:\n",
    "                travel_times = [edge_data[eid]['travel_time'] for eid in path_edges]\n",
    "                geometries = [edge_data[eid]['geometry'] for eid in path_edges]\n",
    "                \n",
    "                paths.append({\n",
    "                    'from_station': start_station_id,\n",
    "                    'to_station': end_station_id,\n",
    "                    'from_node': start_node,\n",
    "                    'to_node': current_node,\n",
    "                    'travel_time': sum(travel_times),\n",
    "                    'edge_ids': path_edges.copy(),\n",
    "                    'num_edges': len(path_edges),\n",
    "                    'geometry': linemerge(geometries) if len(geometries) > 1 else geometries[0]\n",
    "                })\n",
    "            continue\n",
    "        \n",
    "        for edge_info in adjacency.get(current_node, []):\n",
    "            next_node = edge_info['to_node']\n",
    "            next_edge_id = edge_info['edge_id']\n",
    "            \n",
    "            if next_edge_id not in path_edges:\n",
    "                new_path = path_edges + [next_edge_id]\n",
    "                queue.append((next_node, new_path, path_length + 1))\n",
    "\n",
    "simplified_edges = gpd.GeoDataFrame(paths, geometry='geometry', crs=edges_gdf.crs)\n",
    "simplified_edges['path_id'] = np.arange(len(simplified_edges))\n",
    "\n",
    "print(f\"\\n✓ Simplified network: {len(simplified_edges)} paths from {len(edges_gdf)} original edges\")\n",
    "print(f\"  Reduction: {100*(1 - len(simplified_edges)/len(edges_gdf)):.1f}%\")\n",
    "print(f\"  Avg edges/path: {simplified_edges['num_edges'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c38af5",
   "metadata": {},
   "source": [
    "## 6. Calculate Capacities on Simplified Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aa7a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nComputing capacities on simplified paths...\")\n",
    "\n",
    "# Generate stochastic per-train capacity\n",
    "rng = np.random.default_rng(42)\n",
    "train_draw = np.maximum(rng.normal(700.0/1000, 35.0/1000, size=len(edges_gdf)), 0.0)\n",
    "occ_draw = np.clip(rng.normal(0.90, 0.09, size=len(edges_gdf)), 0.0, 1.0)\n",
    "eff_tons = train_draw * occ_draw\n",
    "\n",
    "# Compute capacity for original edges\n",
    "cap_tons_orig = compute_edge_capacity_tons(edges_gdf, tt_col='travel_time', train_tons=eff_tons)\n",
    "edges_gdf['capacity'] = np.where(np.isfinite(cap_tons_orig), cap_tons_orig, 0.0)\n",
    "\n",
    "# Bottleneck capacity for simplified paths\n",
    "def compute_path_capacity(edge_ids_list, edges_with_cap):\n",
    "    if not edge_ids_list:\n",
    "        return 0.0\n",
    "    capacities = [edges_with_cap.loc[edges_with_cap['edge_id'] == eid, 'capacity'].values[0]\n",
    "                  for eid in edge_ids_list\n",
    "                  if not edges_with_cap[edges_with_cap['edge_id'] == eid].empty]\n",
    "    return min(capacities) if capacities else 0.0\n",
    "\n",
    "simplified_edges['capacity'] = simplified_edges['edge_ids'].apply(\n",
    "    lambda x: compute_path_capacity(x, edges_gdf)\n",
    ")\n",
    "\n",
    "print(f\"✓ Capacity range: {simplified_edges['capacity'].min():.0f} - {simplified_edges['capacity'].max():.0f} tons/day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2f86e5",
   "metadata": {},
   "source": [
    "## 7. Plot Simplified Network Capacities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f25400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure EPSG:4326 for plotting\n",
    "simplified_edges_plot = simplified_edges.to_crs(\"EPSG:4326\") if simplified_edges.crs and simplified_edges.crs.to_epsg() != 4326 else simplified_edges.copy()\n",
    "simplified_edges_plot = simplified_edges_plot[simplified_edges_plot.geometry.notna()]\n",
    "simplified_edges_plot = simplified_edges_plot[simplified_edges_plot['capacity'] > 0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "europe_shape.boundary.plot(ax=ax, color='#cccccc', linewidth=0.5, zorder=0)\n",
    "\n",
    "simplified_edges_plot.plot(column='capacity',\n",
    "                          ax=ax,\n",
    "                          linewidth=1.5,\n",
    "                          cmap='YlOrRd',\n",
    "                          legend=True,\n",
    "                          vmin=0,\n",
    "                          vmax=simplified_edges_plot['capacity'].quantile(0.95),\n",
    "                          legend_kwds={'label': 'Capacity (tons/day)', 'shrink': 0.7},\n",
    "                          zorder=2)\n",
    "\n",
    "ax.set_title(f'Simplified Station-to-Station Paths ({len(simplified_edges_plot)} paths)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_xlim(LON_MIN, LON_MAX)\n",
    "ax.set_ylim(LAT_MIN, LAT_MAX)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / 'rail_simplified_capacities.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved capacity plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be4943c",
   "metadata": {},
   "source": [
    "## 8. Run Flow Allocation on Simplified Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023b8c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RUNNING FLOW ALLOCATION ON SIMPLIFIED NETWORK\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Create network dataframe for simplified paths\n",
    "network_df_simplified = pd.DataFrame({\n",
    "    'from_node': simplified_edges['from_station'].values,\n",
    "    'to_node': simplified_edges['to_station'].values,\n",
    "    'edge_id': simplified_edges['path_id'].values,\n",
    "    'travel_time': simplified_edges['travel_time'].values,\n",
    "    'capacity': simplified_edges['capacity'].values,\n",
    "    'flow': 0.0\n",
    "})\n",
    "\n",
    "# Build igraph from simplified network\n",
    "base_graph = ig.Graph.TupleList(\n",
    "    network_df_simplified[['from_node', 'to_node', 'edge_id', 'travel_time']].itertuples(index=False, name=None),\n",
    "    edge_attrs=['edge_id', 'travel_time'],\n",
    "    directed=False\n",
    ")\n",
    "\n",
    "# Aggregate OD by pair and commodity\n",
    "od_pairs = od[['from_node', 'to_node', 'value', 'origin_sector']].groupby(\n",
    "    ['from_node', 'to_node', 'origin_sector'], as_index=False\n",
    ")['value'].sum()\n",
    "\n",
    "# Total per pair\n",
    "pair_totals = od_pairs.groupby(['from_node', 'to_node'], as_index=False)['value'].sum().rename(columns={'value': 'total_value'})\n",
    "od_with_tot = od_pairs.merge(pair_totals, on=['from_node', 'to_node'], how='left')\n",
    "od_with_tot['share'] = np.where(od_with_tot['total_value'] > 0,\n",
    "                                od_with_tot['value'] / od_with_tot['total_value'],\n",
    "                                0.0)\n",
    "\n",
    "# Flow ODs with totals\n",
    "flow_ods_total = od_with_tot[['from_node', 'to_node', 'total_value']].drop_duplicates()\n",
    "flow_ods_total = flow_ods_total.rename(columns={'total_value': 'flow'})\n",
    "\n",
    "# Run capacity-constrained allocation\n",
    "capacity_ods_all, unassigned_paths, network_df_simplified, progress_df = od_flow_allocation_capacity_constrained(\n",
    "    flow_ods=flow_ods_total,\n",
    "    network_dataframe=network_df_simplified,\n",
    "    flow_column='flow',\n",
    "    cost_column='travel_time',\n",
    "    path_id_column='edge_id',\n",
    "    attribute_list=None,\n",
    "    origin_id_column='from_node',\n",
    "    destination_id_column='to_node',\n",
    "    network_capacity_column='capacity',\n",
    "    directed=False,\n",
    "    simple=False,\n",
    "    store_edge_path=True,\n",
    "    graph_base=base_graph,\n",
    "    track_progress=True,\n",
    "    early_stop_share=0.75\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Flow allocation complete\")\n",
    "print(f\"  Assigned: {len(capacity_ods_all)} path groups\")\n",
    "print(f\"  Unassigned: {len(unassigned_paths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d1d95",
   "metadata": {},
   "source": [
    "## 9. Map Flows Back to Original Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00180f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMapping flows back to original edges...\")\n",
    "\n",
    "# Get flows on simplified paths\n",
    "simplified_edges['flow'] = network_df_simplified.set_index('edge_id')['flow'].reindex(\n",
    "    simplified_edges['path_id']\n",
    ").fillna(0.0).values\n",
    "\n",
    "# Initialize flow on original edges\n",
    "edges_gdf['flow'] = 0.0\n",
    "\n",
    "# Map flows from simplified paths to original edges\n",
    "for _, path_row in simplified_edges.iterrows():\n",
    "    edge_ids = path_row.get('edge_ids', [])\n",
    "    flow_val = path_row.get('flow', 0.0)\n",
    "    \n",
    "    if flow_val > 0 and edge_ids:\n",
    "        mask = edges_gdf['edge_id'].isin(edge_ids)\n",
    "        edges_gdf.loc[mask, 'flow'] += flow_val\n",
    "\n",
    "print(f\"✓ Total flow on network: {edges_gdf['flow'].sum():,.0f} tons/day\")\n",
    "print(f\"✓ Edges with flow: {(edges_gdf['flow'] > 0).sum()} / {len(edges_gdf)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3076ec45",
   "metadata": {},
   "source": [
    "## 10. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3714afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare output\n",
    "drop_cols = ['length', 'distance', 'from_infra', 'to_infra']\n",
    "edges_out = edges_gdf.drop(columns=[c for c in drop_cols if c in edges_gdf.columns]).copy()\n",
    "edges_out['flow'] = edges_out['flow'].fillna(0.0).astype(float)\n",
    "\n",
    "# Apply 25% increase (calibration factor)\n",
    "edges_out['flow'] = edges_out['flow'] * 1.25\n",
    "\n",
    "# Save\n",
    "edges_out.to_parquet(OUT_EDGES_DIR / \"rail_edges_with_freight_flow.parquet\", index=False)\n",
    "edges_out[edges_out['flow'] > 0].to_parquet(OUT_EDGES_DIR / \"rail_edges_freight_flow_positive.parquet\", index=False)\n",
    "\n",
    "print(f\"✓ Saved rail_edges_with_freight_flow.parquet\")\n",
    "print(f\"✓ Saved rail_edges_freight_flow_positive.parquet ({(edges_out['flow'] > 0).sum()} edges)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723914ca",
   "metadata": {},
   "source": [
    "## 11. Visualize Final Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed3e6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10), dpi=200)\n",
    "\n",
    "# Basemap\n",
    "europe_shape.boundary.plot(ax=ax, color='#666666', linewidth=0.3, zorder=0)\n",
    "\n",
    "# Reproject for plotting\n",
    "edges_plot = edges_out.to_crs(4326) if edges_out.crs and edges_out.crs.to_epsg() != 4326 else edges_out\n",
    "\n",
    "# Plot with thickness by flow (log scale)\n",
    "plot_edges_by_flow_thickness(\n",
    "    ax, edges_plot, flow_col='flow',\n",
    "    scale='log', log_base=10.0, scale_div=250.0,\n",
    "    classify_method='none', lw_min=0.1, lw_max=3.5\n",
    ")\n",
    "\n",
    "ax.set_xlim(LON_MIN, LON_MAX)\n",
    "ax.set_ylim(LAT_MIN, LAT_MAX)\n",
    "ax.set_title(\"Rail Freight Flow (thousands tons/day)\", fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel(\"Longitude\")\n",
    "ax.set_ylabel(\"Latitude\")\n",
    "ax.set_aspect('equal')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / \"rail_edges_freight_flow.png\", dpi=200)\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved flow visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0819811",
   "metadata": {},
   "source": [
    "## 12. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RAIL FREIGHT FLOW ASSIGNMENT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nNetwork:\")\n",
    "print(f\"  Original edges: {len(edges_gdf):,}\")\n",
    "print(f\"  Simplified paths: {len(simplified_edges):,}\")\n",
    "print(f\"  Reduction: {100*(1 - len(simplified_edges)/len(edges_gdf)):.1f}%\")\n",
    "\n",
    "print(f\"\\nOD Matrix:\")\n",
    "print(f\"  Total OD pairs: {len(od):,}\")\n",
    "print(f\"  Total demand: {od['value'].sum():,.0f} tons/day\")\n",
    "\n",
    "print(f\"\\nFlow Assignment:\")\n",
    "print(f\"  Edges with flow: {(edges_out['flow'] > 0).sum():,} / {len(edges_out):,}\")\n",
    "print(f\"  Total flow on network: {edges_out['flow'].sum():,.0f} tons/day\")\n",
    "print(f\"  Max edge flow: {edges_out['flow'].max():,.0f} tons/day\")\n",
    "print(f\"  Mean edge flow (non-zero): {edges_out[edges_out['flow'] > 0]['flow'].mean():,.0f} tons/day\")\n",
    "\n",
    "print(f\"\\nCapacity:\")\n",
    "print(f\"  Total network capacity: {edges_gdf['capacity'].sum():,.0f} tons/day\")\n",
    "print(f\"  Utilization: {100*edges_out['flow'].sum()/edges_gdf['capacity'].sum():.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
